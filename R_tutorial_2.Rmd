---
title: "Programming with R --- A Beginners’ Guide for Geoscientists"
subtitle: "2 - Data"
author: "Tobias Stephan"
date: "25/01/2022"
output: 
  html_document:
    theme: "united"
    highlight: "tango"
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

---

## Types of Data
### Scalars
```{r data_scalar, echo=TRUE}
a <- 1 # numeric
b <- "Word" # character
c <- TRUE # logical
```

### Vectors
All elements of a vector must have the same mode (numeric, character, etc.).
```{r data_vector1, echo=TRUE}
a <- c(1,2,5.3,6,-2,4) # numeric vector
b <- c("one","two","three") # character vector
c <- c(TRUE,TRUE,TRUE,FALSE,TRUE,FALSE) #logical vector
```

Refer to elements of a vector using subscripts. 
```{r data_vector2, echo=TRUE}
b[2]# second element in vector b
```

#### Multi-column vector
```{r data_vector3, echo=TRUE}
cbind(a, a+1)
```

### Matrices
All columns in a matrix ($m \times n$) must have the same mode (numeric, character, etc.) and the same length. The general format is
```{r data_matrix1, echo=TRUE}
x <- c(1, 0, 0)
y <- c(0, 1, 0)
z <- c(0, 0, 1)

m <- as.matrix(
  cbind(a, b, c)
)
m
```
Identify rows, columns or elements using subscripts. 
```{r data_matrix2, echo=TRUE}
m[,3] # 3rd column of matrix
m[2,] # 2nd row of matrix
m[2,3] # 2nd row, 3rd element
```


### Data frames
A data frame is more general than a matrix, in that different columns can have different modes (numeric, character, factor, etc.). 

```{r dataframe1, echo=TRUE}
mydataframe <- data.frame (a, b, c)
names(mydataframe) <- c('column1', 'column2', 'column3') # header of the data frame
mydataframe
```

There are a variety of ways to identify the elements of a data frame:
```{r dataframe2, echo=TRUE}
mydataframe[2:3] # columns 2 to 3 of data frame
mydataframe[c("column1","column3")] # columns ID and Age from data frame
mydataframe$column2 # variable column2 in the data frame 
mydataframe$column2[2] # 2nd element of column2
```

### Lists
An ordered collection of objects (components). A list allows you to gather a variety of (possibly unrelated) objects under one name. 

```{r list1, echo=TRUE}
mylist <- list(name = "Jean", numbers = x, table = mydataframe)
```

Identify elements of a list using the [[]] convention. 
```{r list2, echo=TRUE}
mylist[[3]] # 2nd component of the list
mylist[["numbers"]] # component named mynumbers in list
```


## Import data
It is possible to load **every** file type into R' workspace. 
To import data sets, you can use the RStudio interface for Import: File > Import Dataset > From...

I recommend to import any data via the R console because if you have to repeat the import, it will save time already after 1 repeat.

### Text files
The most basic import function is `read.table()` which allows to read the most 'character-separated values' (e.g. white space, tab, comma, semi-colon, ... separated tables). The file extension (e.g. .txt, .csv, .dat, ...) does not matter.
```{r import0, eval=FALSE, include=TRUE, echo=TRUE}
read.table("path/to/file/table.txt", header = TRUE, sep = ";", dec = ".")  
```

The following functions are identical to `read.table()` except for the defaults. 
```{r import1, eval=FALSE, include=TRUE, echo=TRUE}
read.csv("path/to/file/table.csv", header = TRUE) #  read ‘comma separated value’ files 
read.csv2("path/to/file/table.csv", header = TRUE) #  same as read.csv() instead uses a comma as decimal point and a semicolon as field separator
```

Some data files are organized by columns that are separated by a defined width (e.g. 3 blank spaces, TAB, ...). In this case, you can use `read.delim()`
```{r import2, eval=FALSE, include=TRUE, echo=TRUE}
read.delim("path/to/file/table.dat", header = TRUE)
```

### Excel
Excel files can be imported by the function `read_excel()` from the *readxl* package. If you want to import the entire table of a excel sheet, you only give the file path, the excel sheet number (or name):
```{r import_excel, eval=FALSE, include=TRUE, echo=TRUE}
readxl::read_excel("path/to/file/table.xlsx", sheet = NULL)
```

### ESRI shape files
```{r import_shp, eval=FALSE, include=TRUE, echo=TRUE}

```

### more
There are some more import functions for special datasets:
```{r import_special, eval=FALSE, include=TRUE, echo=TRUE}
readRDS("path/to/file/table.Rdata") # reading R objects
readClipboard() # read from the MS clipboard (MS only)
```

## Export data
To write data or tables into a file, we can use similar functions as in the import. You now only have to tell which object you want to save:
```{r export, eval=FALSE, include=TRUE, echo=TRUE}
write.table(object, file = "path/to/file/table.txt", sep = " ", row.names = FALSE)
write.csv(object, file = "path/to/file/table.txt", row.names = FALSE)
writeClipboard(object) # write to the MS clipboard (MS only)
saveRDS(object, file = "path/to/file/table.Rdata") # wrtie to a R object file
```

## Explore datasets

For the workshop, I downloaded some U-Pb detrital zircon data from the Rocky Mountains from the Geochron database (http://geochron.org/detritalsearch.php). 

The downloaded excel file is Geochron_sample_download.xls
```{r data1, echo=TRUE, warning=FALSE, message=FALSE}
source("Y:/GIT/R_Geo_workshop/course_stuff.R")
data <- read_geochron("Y:/GIT/R_Geo_workshop/Geochron_sample_download.xls")

meta <- data$meta
isotopes <- data$isotopes
```

```{r dat2, echo=TRUE}
head(meta)
```
```{r data3, echo=TRUE}
head(isotopes)
```

### Rename columns

`rename(data, New_Name = Old_Name)`

```{r rename, echo=TRUE}
require(dplyr)

dplyr::rename(meta, "Oldest_Fraction_Date_Ma" = 'Oldest_Frac._Date_Ma')
```
### Select columns

`select(data, column1, column2, column3)`
```{r select, echo=TRUE}
# select only the columns "Sample_ID", "Longitude", and  "Latitude":
dplyr::select(meta, Sample_ID, Longitude, Latitude)

# select all columns but the column "Sample_Description":
dplyr::select(meta, !Sample_Description)
```


### Filter tables

`filter(data. column == value)`
 such filters can include any of the Logical Operators (or "Booleans"), such as `==`, `>`, `>=`, or `!=`:

```{r filter, echo=TRUE}
# only samples from British Columbia:
dplyr::filter(meta, Province == "British Columbia")
```

### Calculate a new column
New columns can be calculated the following:
`mutate(data, new_column1 = "Word", new_column2 = old_column1 + 1, new_column_3 = old_column2 / olc_column3)`.
```{r mutate, message = FALSE, warning = FALSE}
#calculate the concordance of the U-Pb ages:
x <- dplyr::mutate(isotopes, conc = ifelse(
      t.Pb206U238 > 1000,
      t.Pb206U238 / t.Pb207Pb206,
      t.Pb206U238 / t.Pb207U235
      )
    )
dplyr::select(x, Fraction_ID, conc)
```

> `ifelse()` does a calculation depending on a condition.
> `ifelse(condition, this, that)` literally means "If condition is TRUE does this. If not, do that".

### Pipe commands
A sequence of functions omn the same object can be expressed like the following:

```{r pipe1, echo=TRUE}
# one after the other
x <-
  dplyr::mutate(
    isotopes,
    conc = ifelse(
      t.Pb206U238 > 1000,
      t.Pb206U238 / t.Pb207Pb206,
      t.Pb206U238 / t.Pb207U235
    )
  )
x <- dplyr::select(x, Fraction_ID, conc)
x <- dplyr::filter(x, conc >= 0.85 & conc <= 1.05)

#or in one step
y <-
  dplyr::filter(
    dplyr::select(
      dplyr::mutate(
        isotopes,
        conc = ifelse(
      t.Pb206U238 > 1000,
      t.Pb206U238 / t.Pb207Pb206,
      t.Pb206U238 / t.Pb207U235
    )
      ),
      Fraction_ID,
      conc
    ),
    conc >= 0.85 & conc <= 1.05
  )

identical(x, y) # test if both sequences did the same job and produce the identical result
```
As you can see both ways require a lot of typing and are complicated to read.

The package *dplyr* offers a convenient way to do a sequcence of functions by using the "pipe" operator `%>%`:
```{r pipe2, echo=TRUE}
isotopes %>%
  mutate(conc = ifelse(
      t.Pb206U238 > 1000,
      t.Pb206U238 / t.Pb207Pb206,
      t.Pb206U238 / t.Pb207U235
      )
    ) %>%
  select(Fraction_ID, conc) %>%
  filter(conc >= 0.85 & conc <= 1.05)
```

### Merge tables
```{r merge, message = FALSE, warning = FALSE}
require(dplyr)
combined <- dplyr::left_join(isotopes, meta, by = "Sample_ID")
```


### Grouped calculations or statistics
```{r group, message = FALSE, warning = FALSE}
combined %>% 
  group_by(Sample_ID) %>%
  summarise(length(na.omit(t.Pb206U238)))
```



[previous course: Basics](R_turorial_1.html) | [next course: Decriptive statistics](R_turorial_3.html)
